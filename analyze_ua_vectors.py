import os
import torch
import argparse
import glob
import numpy as np
from tabulate import tabulate

def analyze_single_vector(file_path):
    """
    åˆ†æå•ä¸ª .pt æ–‡ä»¶çš„ç»Ÿè®¡ä¿¡æ¯
    """
    try:
        data = torch.load(file_path, map_location="cpu")
    except Exception as e:
        return None, f"Error loading: {str(e)}"

    # æ£€æŸ¥æ˜¯å¦ä¸º UA æ–¹æ³•ä¸”åŒ…å«ç»Ÿè®¡ä¿¡æ¯
    if data.get("method") not in ["ua", "mixture_ua"]: 
        return None, "Not a UA vector file"
    
    stats = data.get("statistics", {})
    if not stats:
        return None, "No statistics found in file"

    # è·å–æ ¸å¿ƒæ•°æ®
    shrinkage_coeffs = stats.get("shrinkage_coefficients") # Lambda
    tau_squared = stats.get("tau_squared", 1.0)
    mean_vec = stats.get("mean_vector")
    ua_vec = stats.get("ua_vector")
    
    if shrinkage_coeffs is None:
        return None, "Missing shrinkage coefficients"

    # è½¬æ¢ä¸º numpy
    coeffs = shrinkage_coeffs.numpy()
    
    # è®¡ç®—æŒ‡æ ‡
    mean_lambda = np.mean(coeffs)
    pct_preserved = np.sum(coeffs > 0.8) / len(coeffs) * 100 # è®¤ä¸ºæ˜¯ä¿¡å·
    pct_suppressed = np.sum(coeffs < 0.2) / len(coeffs) * 100 # è®¤ä¸ºæ˜¯å™ªå£°
    
    norm_ratio = 0.0
    if mean_vec is not None and ua_vec is not None:
        norm_orig = torch.norm(mean_vec).item()
        norm_ua = torch.norm(ua_vec).item()
        if norm_orig > 1e-9:
            norm_ratio = norm_ua / norm_orig

    # ç»™å‡ºå»ºè®®
    suggestion = "Keep"
    if pct_preserved > 95:
        suggestion = "â¬‡ï¸ Decrease tauÂ² (Too little denoising)"
    elif pct_suppressed > 95:
        suggestion = "â¬†ï¸ Increase tauÂ² (Signal loss risk)"
    elif pct_preserved < 5 and pct_suppressed < 95:
        # è¿™ç§æƒ…å†µæ¯”è¾ƒå°‘è§ï¼Œå¯èƒ½æ˜¯è¿‡åº¦å¹³æ»‘ä½†æ²¡å®Œå…¨æŠ‘åˆ¶
        suggestion = "â¬†ï¸ Increase tauÂ² (Over-regularized)"
    else:
        suggestion = "âœ… Balanced (Fine-tune)"

    # ä»æ–‡ä»¶åè§£æ Layer
    filename = os.path.basename(file_path)
    try:
        layer_str = filename.split("_L")[1].split(".")[0].split("_")[0]
        layer_idx = int(layer_str)
    except:
        layer_idx = -1

    # ã€ä¿®å¤ç‚¹ã€‘ï¼šé”®åå¿…é¡»ä¸ main å‡½æ•°ä¸­çš„ headers å®Œå…¨ä¸€è‡´
    return {
        "Layer": layer_idx,
        "Tau^2": tau_squared,
        "Mean Î»": mean_lambda,
        "Kept%": pct_preserved,  # ä¿®å¤ï¼šå»æ‰ (>0.8) åç¼€
        "Cut%": pct_suppressed,  # ä¿®å¤ï¼šå»æ‰ (<0.2) åç¼€
        "Norm Ratio": norm_ratio,
        "Suggestion": suggestion,
        "File": filename
    }, None

def main():
    parser = argparse.ArgumentParser(description="Analyze UA CoT Vectors and suggest hyperparameters.")
    parser.add_argument("--dataset", type=str, required=True, help="Dataset name (e.g., gsm8k, math_hard)")
    parser.add_argument("--output_dir", type=str, default="./outputs", help="Directory containing vectors")
    args = parser.parse_args()

    # æœç´¢æ–‡ä»¶
    search_pattern = os.path.join(args.output_dir, f"ua_{args.dataset}_L*.pt")
    files = glob.glob(search_pattern)
    files.sort() 

    if not files:
        print(f"No UA vector files found for dataset '{args.dataset}' in {args.output_dir}")
        return

    print(f"\nAnalyzing {len(files)} vectors for dataset: {args.dataset}\n")

    results = []
    for f in files:
        res, err = analyze_single_vector(f)
        if res:
            results.append(res)
        else:
            if "Not a UA vector" not in err: 
                print(f"Skipping {os.path.basename(f)}: {err}")

    # æŒ‰å±‚å·æ’åº
    results.sort(key=lambda x: x["Layer"])

    # æ‰“å°è¡¨æ ¼
    if results:
        headers = ["Layer", "Tau^2", "Mean Î»", "Kept%", "Cut%", "Norm Ratio", "Suggestion"]
        
        # æ„å»ºè¡¨æ ¼æ•°æ®
        table_data = []
        for r in results:
            row = []
            for h in headers:
                val = r.get(h, "N/A") # ä½¿ç”¨ get é˜²æ­¢ KeyError
                if h == "Kept%" or h == "Cut%":
                    row.append(f"{val:.1f}%")
                elif h == "Mean Î»" or h == "Norm Ratio":
                    row.append(f"{val:.3f}")
                elif h == "Tau^2":
                    row.append(f"{val:.2f}")
                else:
                    row.append(val)
            table_data.append(row)

        print(tabulate(table_data, headers=headers, tablefmt="simple_grid"))
        
        print("\n" + "="*60)
        print("ğŸ’¡ Guide to Adjustment:")
        print("  â€¢ Kept%: Dimensions with Î» > 0.8 (High Confidence).")
        print("  â€¢ Cut%:  Dimensions with Î» < 0.2 (Noise).")
        print("  â€¢ Rule:  If Kept% > 95% -> Decrease tau^2 (0.1, 0.01)")
        print("           If Cut% > 95%  -> Increase tau^2 (2.0, 5.0)")
        print("="*60 + "\n")
    else:
        print("No valid UA vectors found to analyze.")

if __name__ == "__main__":
    main()